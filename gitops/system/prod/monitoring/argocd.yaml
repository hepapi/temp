apiVersion: argoproj.io/v1alpha1
kind: ApplicationSet
metadata:
  name: prometheus
  namespace: argocd
spec:
  generators:
    - list:
        elements:
          - cluster: dev    
            grafana: "true"
            version: 65.6.0
            domain: "xxx.com"
          - cluster: prod    
            grafana: "false"
            version: 65.6.0
            domain: "xxx.com"
            
  template:
    metadata:
      name: '{{cluster}}-prometheus'
    spec:
      syncPolicy:
        automated:
          selfHeal: true
          prune: false
        syncOptions:
          - Validate=true
          - CreateNamespace=true
          - PrunePropagationPolicy=foreground
          - PruneLast=true
          - ServerSideApply=true
      destination:
          namespace: monitoring
          name: '{{cluster}}'
      project: default
      source:
        repoURL: https://prometheus-community.github.io/helm-charts
        targetRevision: '{{version}}'
        chart: kube-prometheus-stack
        helm:
          values: |
            global:
              rbac:
                create: true
                createAggregateClusterRoles: false
                pspEnabled: true
                pspAnnotations:
                    seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'
            kube-state-metrics:
              podSecurityPolicy:
                enabled: true
                annotations:
                  seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'
            alertmanager:
              enabled: true
              ingress:
                annotations:
                  kubernetes.io/ingress.class: nginx
                enabled: true
                hosts:
                - alertmanager.{{domain}}
            crds:
              enabled: true
            grafana:
              enabled: {{grafana}}
              datasources:
                datasources.yaml:
                  apiVersion: 1
                  datasources:
                  - access: proxy
                    editable: true
                    isDefault: false
                    jsonData:
                      timeInterval: 5s
                    name: dev
                    type: prometheus
                    url: http://prometheus.xxx.com
                  - access: proxy
                    editable: true
                    isDefault: false
                    jsonData:
                      timeInterval: 5s
                    name: prod
                    type: prometheus
                    url: http://prometheus.xxx.com
              adminPassword: xxxx.123
              defaultDashboardsEditable: true
              defaultDashboardsTimezone: Europe/Istanbul
              ingress:
                annotations:
                  kubernetes.io/ingress.class: nginx
                enabled: true
                hosts:
                - monitoring.{{domain}}
                path: /
            prometheus:
              tolerations:
                - key: "CriticalAddonsOnly"
                  operator: "Equal"
                  value: "true"
                  effect: "NoExecute"
              enabled: true
              ingress:
                annotations:
                  kubernetes.io/ingress.class: nginx
                enabled: true
                hosts:
                - prometheus.{{domain}}
              prometheusSpec:
                retention: 30d
                retentionSize: 45GB
                storageSpec:
                  volumeClaimTemplate:
                    spec:
                      resources:
                        requests:
                          storage: 50Gi 
            nodeExporter:
              enabled: true
              tolerations:
                - key: "CriticalAddonsOnly"
                  operator: "Equal"
                  value: "true"
                  effect: "NoExecute"                 
            prometheusOperator:
              admissionWebhooks:
                  enabled: false
                  patch:
                    enabled: false
                    prometheusOperator:
              tls:
                enabled: false
            defaultRules:
              create: true
              rules:
                alertmanager: false
                etcd: false
                configReloaders: true
                general: true
                k8sContainerCpuUsageSecondsTotal: true
                k8sContainerMemoryCache: true
                k8sContainerMemoryRss: true
                k8sContainerMemorySwap: true
                k8sContainerResource: true
                k8sContainerMemoryWorkingSetBytes: true
                k8sPodOwner: true
                kubeApiserverAvailability: false
                kubeApiserverBurnrate: false
                kubeApiserverHistogram: false
                kubeApiserverSlos: false
                kubeControllerManager: false
                kubelet: false
                kubeProxy: false
                kubePrometheusGeneral: false
                kubePrometheusNodeRecording: false
                kubernetesApps: true
                kubernetesResources: true
                kubernetesStorage: true
                kubernetesSystem: true
                kubeSchedulerAlerting: false
                kubeSchedulerRecording: false
                kubeStateMetrics: false
                network: false
                node: true
                nodeExporterAlerting: true
                nodeExporterRecording: true
                prometheus: false
                prometheusOperator: false
                windows: false
            additionalPrometheusRulesMap:
             custom-rules:
               groups:
                - name: custom-rules
                  rules:
                  - alert: PodCrashLoopBackOff
                    annotations:
                      description: Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container
                        }}) is restarting {{ printf "%.2f" $value }} times / 11 minutes.
                      summary: Pod is crash looping.
                    expr: |-
                      increase(kube_pod_container_status_restarts_total{job="kube-state-metrics"}[10m]) > 0
                      and
                      kube_pod_container_status_waiting{job="kube-state-metrics"} == 1
                    for: 30s
                    labels:
                      severity: critical
                  - alert: KubernetesContainerOomKiller
                    expr: (kube_pod_container_status_restarts_total - kube_pod_container_status_restarts_total offset 10m >= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}[10m]) == 1
                    for: 0m
                    labels:
                      severity: warning
                    annotations:
                      summary: Kubernetes Container oom killer (instance {{ $labels.instance }})
                      description: "Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }} times in the last 10 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
                  - alert: KubernetesJobFailed
                    expr: kube_job_status_failed > 0
                    for: 0m
                    labels:
                      severity: warning
                    annotations:
                      summary: Kubernetes Job failed (instance {{ $labels.instance }})
                      description: "Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
                  - alert: KubernetesStatefulsetDown
                    expr: kube_statefulset_replicas != kube_statefulset_status_replicas_ready > 0
                    for: 1m
                    labels:
                      severity: critical
                    annotations:
                      summary: Kubernetes StatefulSet down (instance {{ $labels.instance }})
                      description: "StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} went down\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
                  - alert: KubernetesPodCrashLooping
                    expr: increase(kube_pod_container_status_restarts_total[1m]) > 3
                    for: 2m
                    labels:
                      severity: warning
                    annotations:
                      summary: Kubernetes pod crash looping (instance {{ $labels.instance }})
                      description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is crash looping\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
                  - alert: KubernetesReplicasetReplicasMismatch
                    expr: kube_replicaset_spec_replicas != kube_replicaset_status_ready_replicas
                    for: 10m
                    labels:
                      severity: warning
                    annotations:
                      summary: Kubernetes ReplicaSet replicas mismatch (instance {{ $labels.instance }})
                      description: "ReplicaSet {{ $labels.namespace }}/{{ $labels.replicaset }} replicas mismatch\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
                  - alert: KubePodMemoryUsage
                    expr: sum(container_memory_usage_bytes{image!="", pod!=""}) by (pod) / sum(kube_pod_container_resource_limits{resource="memory", unit="byte", pod!=""}) by (pod) * 100 > 90
                    for: 10m
                    labels:
                      severity: warning
                    annotations:
                      summary: "High memory usage detected in pod {{ $labels.pod }}"
                      description: "Pod {{ $labels.pod }} memory usage is above 90% for the last 10 minutes."
                  - alert: PodHighCpuUsage
                    expr: sum(rate(container_cpu_usage_seconds_total{image!="", pod!=""}[2m])) by (pod) / sum(kube_pod_container_resource_limits{resource="cpu", unit="core", pod!=""}) by (pod) * 100 > 90
                    for: 2m
                    labels:
                      severity: critical
                    annotations:
                      summary: "High CPU usage detected in pod {{ $labels.pod }}"
                      description: "Pod {{ $labels.pod }} CPU usage is above 70% for the last 2 minutes."
                  - alert: KubePodMemoryUsageParasut
                    expr: sum by (namespace,pod) (container_memory_usage_bytes{image!="",pod!="", namespace=~"parasut.*"}) / sum by (namespace,pod) (kube_pod_container_resource_limits{namespace=~"parasut.*", pod!="", resource="memory", unit="byte"}) * 100 > 90
                    for: 1m
                    labels:
                      severity: critical
                    annotations:
                      summary: "High memory usage detected in pod {{ $labels.pod }}"
                      description: "Pod {{ $labels.pod }} memory usage is above 90% for the last 1 minutes."
                  - alert: KubernetesClientCertificateExpiresNextWeek2
                    expr: apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 365*24*60*60
                    for: 0m
                    labels:
                      severity: warning
                    annotations:
                      summary: Kubernetes client certificate expires next week (instance {{ $labels.instance }})
                      description: "A client certificate used to authenticate to the apiserver is expiring next week .\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
                  - alert: KubernetesClientCertificateExpiresSoon2
                    expr: apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 24*60*60
                    for: 0m
                    labels:
                      severity: critical
                    annotations:
                      summary: Kubernetes client certificate expires soon (instance {{ $labels.instance }})
                      description: "A client certificate used to authenticate to the apiserver is expiring in less than 24.0 hours.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"